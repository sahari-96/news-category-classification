# -*- coding: utf-8 -*-
"""fasttext (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A_mSXOifhPFFWg1TTuQFRIh-ruUeYpCt
"""

#we have to install fasttext
!pip install fasttext

import fasttext

import pandas as pd
import numpy as np

#import data
from google.colab import drive
drive.mount('/content/drive')
train = pd.read_csv("/content/drive/MyDrive/train.csv")
test = pd.read_csv("/content/drive/MyDrive/test.csv")

train.head()

train_content = train['cleaned_content'].values
train_title = train['cleaned_title'].values
train_author = train['author'].values
train_dates = train['date'].values
train_label = train['label'].values

test_content = test['cleaned_content'].values
test_title = test['cleaned_title'].values
test_author = test['author'].values
test_dates = test['date'].values
test_label = test['label'].values

#reshape labels for fasttext model
transform_label = lambda x : "__label__" + str(x) 
vfunc = np.vectorize(transform_label)
train_label = vfunc(train_label)
test_label = vfunc(test_label)

train_label

training_data = np.stack((train_label, train_content, train_title, train_author), axis = -1)

test_data = np.stack((test_label, test_content, test_title, test_author), axis = -1)

training_data[:, 0]

test_data[:, 0]

training_data[0]

# create the input text file for fasttext

def create_input_text(features, data):
    fasttext_text = np.empty(len(data), dtype = "object")
    for i in range(len(data)):
        content = data[i][1].replace('\n', ' ')
        concated_text = content 
        for feature in features:
            concated_text = concated_text + " /***/ " + str(data[i][feature])
        fasttext_text[i] = concated_text
    return fasttext_text

# 2: title
# 3: author

features = [2]
training_text = create_input_text(features, training_data)
test_text = create_input_text(features, test_data)

training_text[0]

test_text[1]

#make txt files for train and test data
training_text_whole = np.stack((training_data[:, 0], training_text), axis=-1)
test_text_whole = np.stack((test_data[:, 0], test_text), axis=-1)
np.savetxt("training_text.txt", training_text_whole, fmt = "%s  %s")
np.savetxt("test_text.txt", test_text_whole, fmt = "%s  %s")

#define model
model = fasttext.train_supervised(input="training_text.txt", epoch=25, lr=1, wordNgrams=3)

# Dump model
model.save_model("fastText_model.bin")

#getting accuracy
model.test("test_text.txt")

n = len(test_text_whole)
prediction_label = np.empty(len(test_text_whole), dtype = "object")

for i in range(n):
    prediction_label[i] = model.predict(test_text_whole[i][1])[0][0]

true_label = test_text_whole[:, 0]

#getting presicion, recall, fscore
from sklearn.metrics import precision_recall_fscore_support
precision_recall_fscore_support(true_label, prediction_label, average='weighted')

precision_recall_fscore_support(true_label, prediction_label, average='macro')

precision_recall_fscore_support(true_label, prediction_label, average='micro')

"""#### confusion matrix"""

from sklearn.metrics import confusion_matrix
from sklearn.metrics import multilabel_confusion_matrix
from sklearn.metrics import classification_report

labels = ['__label__0','__label__1']

cm = confusion_matrix(true_label, prediction_label, labels=labels)

print(cm)

import seaborn as sns
import matplotlib.pyplot as plt
fig, ax = plt.subplots() 
sns.heatmap(cm/np.sum(cm), annot=True, 
            fmt='.2%', cmap='Blues', xticklabels=labels, yticklabels=labels)

print(classification_report(true_label, prediction_label, labels=labels, zero_division=0))

"""### FastText Performance:

| Features             | Precision | Recall | F1-score | Accuracy |
|--------------------| ------------|--------|----------|----------|
| content             | 69.26 | 69.10 | 69.17 | 70.04 |
| content + title         | 69.88 | 69.80 | 69.84 | 70.64 |
| content + title + author   | 69.53 | 69.40 | 69.46 | 70.31 |

### Bert and Roberta and XLNet Performance: 

|Model | Features             | Precision | Recall | F1-score | Accuracy | Average Loss|
|--------|--------------------| ------------|--------|----------|----------|--------------|
|Bert | content + title         | 72.69 | 83.38 | 77.67  | 79.78 | 0.42  | 
|RoBerta | content + title         | 69.11 | 75.09 | 70.77 | 79.42 | 0.42 |
|XLNet | content + title       | 73.20 | 78.37 | 75.70 | 78.34 | 0.43
"""